# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oc4RlIrI5cIzWSDDYdp2XH_lGbWPKWgj
"""

!gdown 1nxR07ebVNc5bSgfTQjeUcAoyoaNuuH6s

import pandas as pd

# Load dataset
df = pd.read_csv('./IMDB-Dataset.csv')
# adding error_bad_lines=False will allow the parser to skip any problematic lines

# Remove duplicate rows
print(df.duplicated().sum())
dg = df.drop_duplicates()

# Display the cleaned dataset
dg.head()  # Use dg to see all rows or head() to see the first few rows



"""Import thư viện"""

!pip install contractions
!pip install beautifulsoup4
!pip install nltk

import re
import string
import nltk
nltk.download('stopwords')
nltk.download('wordnet')
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from bs4 import BeautifulSoup
import contractions



stop = set(stopwords.words('english'))
def expand_contractions(text):
    return contractions.fix(text)


def preprocess_text(text):
    wl = WordNetLemmatizer()

    soup = BeautifulSoup(text, "html.parser")  # Removing HTML tags
    text = soup.get_text()

    text = expand_contractions(text)  # Expanding contractions

    emoji_clean = re.compile("["
                             u"\U0001F600-\U0001F64F"  # emoticons
                             u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                             u"\U0001F680-\U0001F6FF"  # transport & map symbols
                             u"\U0001F1E0-\U0001F1FF"  # flags
                             u"\u2702-\u27B0"
                             u"\u24C2-\U0001F251"
                             "]+", flags=re.UNICODE)
    text = emoji_clean.sub(r'', text)  # Remove emojis and symbols

    text = re.sub(r'\.(?=\S)', '. ', text)  # Add space after full stops

    text = re.sub(r'http\S+', '', text)  # Remove URLs

    text = "".join([word.lower() for word in text if word not in string.punctuation])  # Remove punctuation and lowercase

    text = " ".join([wl.lemmatize(word) for word in text.split() if word not in stop and word.isalpha()])  # Lemmatization, remove stopwords, keep only alphabetic words

    return text

# df[’review ’] = df[’review ’]. apply ( preprocess_text )

"""lượng data trong csdl có 50% là tốt và 50% là sấu"""

# Tách các từ và lấy các từ duy nhất trong toàn bộ các review
df['review'] = df['review'].apply(preprocess_text)

vocab = set()
df['review'].apply(lambda x: vocab.update(x.split()))

# Kích thước từ điển
vocab_size = len(vocab)
print(f'Kích thước từ điển sau tiền xử lý: {vocab_size}')

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Creating autopct function
def func(pct, allvalues):
    absolute = int(pct / 100. * np.sum(allvalues))
    return "{:.1f}%\n({:d})".format(pct, absolute)

# Assuming 'df' is a DataFrame with a 'sentiment' column
freq_pos = len(df[df['sentiment'] == 'positive'])
freq_neg = len(df[df['sentiment'] == 'negative'])

# Data for pie chart
data = [freq_pos, freq_neg]
labels = ['positive', 'negative']

# Create pie chart
fig, ax = plt.subplots(figsize=[11, 7])
plt.pie(x=data, autopct=lambda pct: func(pct, data), explode=[0.0025] * 2,
        pctdistance=0.5, colors=[sns.color_palette()[0], 'tab:red'],
        textprops={'fontsize': 16})

# Set labels and legend
plt.legend(labels, loc="best", prop={'size': 14})

# Save the pie chart as a PNG file
plt.savefig("PieChart.png")

# Show the pie chart
plt.show()

"""Thống kê độ dài của các mẫu cho mỗi class."""

# Tính độ dài của từng review trong cột 'review'
words_len = df['review'].str.split().map(lambda x: len(x))

# Tạo bản sao của DataFrame để thêm cột độ dài
df_temp = df.copy()
df_temp['words length'] = words_len

# Vẽ biểu đồ phân bố số từ cho các review tích cực
hist_positive = sns.displot(
    data=df_temp[df_temp['sentiment'] == 'positive'],
    x="words length", hue="sentiment", kde=True, height=7, aspect=1.1, legend=False
).set(title='Words in positive reviews')

plt.show(hist_positive)

# Vẽ biểu đồ phân bố số từ cho các review tiêu cực
hist_negative = sns.displot(
    data=df_temp[df_temp['sentiment'] == 'negative'],
    x="words length", hue="sentiment", kde=True, height=7, aspect=1.1, legend=False, palette=['red']
).set(title='Words in negative reviews')

plt.show(hist_negative)

# Vẽ biểu đồ KDE cho số lượng từ trong tất cả các review, phân biệt theo sentiment
plt.figure(figsize=(7, 7.1))
kernel_distribution_number_words_plot = sns.kdeplot(
    data=df_temp, x="words length", hue="sentiment", fill=True, palette=[sns.color_palette()[0], 'red']
).set(title='Words in reviews')

plt.legend(title='Sentiment', labels=['negative', 'positive'])
plt.show(kernel_distribution_number_words_plot)

"""Chia tập train và test:"""

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder

# Mã hóa các nhãn sentiment (cảm xúc)
label_encode = LabelEncoder()
y_data = label_encode.fit_transform(df['sentiment'])

# Chia tập dữ liệu thành tập huấn luyện và kiểm tra (80% huấn luyện, 20% kiểm tra)
x_train, x_test, y_train, y_test = train_test_split(
    df['review'], y_data, test_size=0.2, random_state=42
)

# Khởi tạo TfidfVectorizer
tfidf_vectorizer = TfidfVectorizer(max_features=10000)

# Fit TfidfVectorizer với văn bản thô
tfidf_vectorizer.fit(x_train, y_train)

# Biến đổi dữ liệu văn bản thành ma trận TF-IDF
x_train_encoded = tfidf_vectorizer.transform(x_train)
x_test_encoded = tfidf_vectorizer.transform(x_test)

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# Khởi tạo mô hình Decision Tree với tiêu chuẩn 'entropy'
dt_classifier = DecisionTreeClassifier(
    criterion='entropy',
    random_state=42
)

# Huấn luyện mô hình với dữ liệu đã được mã hóa bằng TF-IDF
dt_classifier.fit(x_train_encoded, y_train)

# Dự đoán trên tập kiểm tra
y_pred = dt_classifier.predict(x_test_encoded)

# Tính độ chính xác của mô hình
accuracy = accuracy_score(y_test, y_pred)
print(f"Decision Tree Accuracy: {accuracy:.4f}")

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Khởi tạo mô hình Random Forest với random_state=42
rf_classifier = RandomForestClassifier(random_state=42)

# Huấn luyện mô hình với dữ liệu huấn luyện đã được mã hóa bằng TF-IDF
rf_classifier.fit(x_train_encoded, y_train)

# Dự đoán trên tập kiểm tra
y_pred = rf_classifier.predict(x_test_encoded)

# Tính độ chính xác của mô hình
accuracy = accuracy_score(y_test, y_pred)
print(f"Random Forest Accuracy: {accuracy:.4f}")